# SSD算法以及Faster-RCNN实现通过X光图片检测充电宝

## 一.问题描述

		需要训练目标检测模型，使用这个目标检测模型检测出测试集中每张图片中的危险品（例如输入模型一张测试图片，最终输出这张图片中所有危险品的类别以及位置坐标）。在最后测试结果时，会使用测试集来进行测试，测试集和训练集的文件结构是相同的，但测试集没有给出，所以请从训练集中划分一个验证集出来。在验证集上验证自己模型的效果。



## 二.任务一（遮挡问题）

		数据集中的安检图片都存在不同等级的遮挡问题，遮挡会严重影响检测器识别危险品的准确率。如何解决严重遮挡条件下模型检测危险品问题是一个热点。
	
		安检机返回的x光图像为RGB彩色图像。训练集中的危险品包括带电芯充电宝和不带电芯充电宝两个类别。训练集中共有6000张图片（带电芯充电宝和不带电芯充电宝各3000张，且测试集根据遮挡等级分为了1,2,3种不同的遮挡等级，不同遮挡等级的示意图见图1）。每张图片都拥有一个危险品所在的位置标注文件，标注文件里的每行表示（危险品的名称，危险品位置的左上坐标，危险品位置的右下坐标）。
	
		最后将修改测试文件中的数据集路径，将其改为测试集所在的路径。之后分别得出3个遮挡等级各自的map。根据3个map与对应遮挡等级的权重（等级1权重0.2，等级2权重0.3，等级3权重0.5）相乘后得到的分数相加得出最终的分数。

## 三.作业流程
		分别使用了SSD与Faster-RCNN两种算法进行目标检测，试图分析比较两种算法的异同以及在本数据集上的表现。在进行训练前，将数据集按照VOC2007的模式进行改变，之后进行训练，对比结果，改变参数优化模型。

## 四.SSD模型介绍

		本项目主要采用的一种解决目标检测问题的方法为SSD模型，来源于Wei Liu的论文《SSD: Single Shot MultiBox Detector》，主要的思想和特点在于:
- 目标检测的定义理解为物体多个边界框如何进行有效回归的问题，在处理过程中会对网络框进行置信度得分设置，较高的置信度意味着该显示框匹配对象的可能性越高。
+ 在模型优化和回归过程中，通过反向传播优化预测框和Ground Truth的相似度，从位置和分类两个角度进行分析和考虑。

+ 增加边界框的可拓展型，设置多重比例的预选框，但在物体类别确定时，Bounding Box的数量不会随之上升，易拓展于较大的数据集中。

  #### 1.网络结构介绍

  ![img](https://img-blog.csdnimg.cn/20190307162727290.png)

		本项目在将VGG16作为Base NetWork的基础上，使用6个不同特征图检测不同尺度的目标，低层预测小目标，高层预测大目标。
  #### 2.多种宽高比预测框
  
  ![img](https://img-blog.csdn.net/201808251642571?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpYW5xaW5nMTM1Nzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
  
			SSD模型采用特征金字塔，从不同尺度的特征图下面来预测目标分类与位置。
			在金字塔结构中每一部分都有3*3的卷积来进行预测，在某个位置上得到一个预测值，这个预测值可能是一个分类的得分，也可能是现对于默认框的的位置偏差。从SSD网络结构图中可以看出来conv6-2，conv7-2，conv8-2，conv9-2，fc7，conv4-2。
			尺度线框的设定方式为：

$$
S_k=S_{min}+\frac{S_{max}-S{min}}{m-1}(K-1)
$$
$$
a_r\in{1,2,3,\frac{1}{2},\frac{1}{3}}
$$
$$
\omega_k^a=\sqrt{a_r}  h_k^a=\frac{s_k}{\sqrt{a_r}}
$$

  #### 3.损失函数
		损失函数定义为位置误差（locatization loss,loc）与置信度误差（confidence loss,conf）的加权和：
$$
L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))
$$

		对于位置误差，其采用Smooth L1 loss,对于置信度误差，其采用softmax loss。


  #### 4.预测过程
		预测过程中对于每个预测框，首先根据类别置信度确定其类别（置信度最大者）与置信度值，并过滤掉属于背景的预测框。
		然后根据置信度阈值（如0.5）过滤掉阈值较低的预测框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数（解码后一般还需要做clip，防止预测框位置超出图片）。解码之后，一般需要根据置信度进行降序排列，
		然后仅保留top-k（如400）个预测框。最后就是进行NMS算法，过滤掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果了。

## 五.Faster-RCNN模型简介
		与SSD算法属于One Stage目标检测算法不同的是，Faster-RCNN属于Two Stage算法。Two Stage目标检测算法先进行区域生成（region proposal，RP）（一个有可能包含待检物体的预选框），再通过卷积神经网络进行样本分类。One Stage算法则不用进行RP,直接在网络中提取特征来预测物体分类和位置。

  #### 1.Faster-RCNN结构

  ![img](https://miro.medium.com/max/542/1*wwKCoG-VtBycFeACBES4nA.jpeg)

		Faster-RCNN是两个网络的结合：用于区域生成(RP)的区域生成网络(RPN, Region Proposal Network)，以及一个用RPN生成的区域来检测目标的网络。与Fast-RCNN的主要区别也就在于，Fast-CNN使用Selective Search来生成区域建议，而Faster-RCNN使用RPN. RPN与目标检测网络共享大部分的计算时，RPN生成区域建议的时间消耗要远小于Selective Search.简单总结RPN就是，RPN对区域框（叫做Anchors）进行排序，然后建议出最可能包含目标的那几个。

  #### 2.Anchors
		Anchors在Faster-RCNN中的角色至关重要。它本质是一个box，在Faster-RCNN的默认配置中，以图像某一像素点为中心的Achors共有9个，下图是以(320,320)为中心的9个Anchors：

  ![img](https://miro.medium.com/max/702/1*IS_9HnkfDdF00nID6xxF_A.png)

		三种颜色代表着不同的比例(Scales)或大小(Sizes): 128*128, 256*256, 512*512.
		以红色为例，红色颜色的框对应着不同的高宽比，分别为:1:1, 1:2和2:1.

		如果我们以每16为步长选择一个位置，这将会有1989（39*51）个位置。这将导致17901（1989*9）个框需要考虑。绝对大小几乎不小于Sliding Window和Pyramid的结合。于是我们就可以知道为什么它具有其他state-of-art方法一样好的覆盖范围的。这样的优点是，Faster-RCNN中的RP方法，能显著减少计算数量。
	
  #### 3.RPN
		RPN的输出是一堆框或者叫区域建议，用来被后续的分类器和回归器检验，来最终检查目标是否出现。更准确地说，RPN来预测Anchors是背景还是前景的可能，并对Anchors进行优化。

  - 背景和前景的分类器：训练分类器的第一步是制作训练数据集。分类器的基本思想在于给anchors一个label，将与真实boxes与较高重合度的anchors标记为前景，有较低重合度的则标记为背景。现在Anchors都有了自己的label。
  - 边界框(Bouding Box)的回归器：顺着label anchors的过程，还可以根据相似的标准来挑选Anchors，以使回归器优化。需要注意的是，被标记为背景的anchor不应该被添加到回归器中，因为它们没有ground truth. RPN的总体损失是分类损失和回归损失的组合，使用的损失函数是：
  ![img](https://miro.medium.com/max/650/1*jA7B88OXz2FJRKCHcOQ2bg.png)

  #### 4.ROI Pooling
		在RPN之后，我们得到了具有不同大小的建议区域。不同大小的区域意味着不容大小的CNN feature map.要构建一个有效的结构来处理不同大小的特征并不容易。感兴趣区域池化(Region of Interest Pooling, ROI)可以通过将feature maps缩小为同一大小来简化问题。与固定大小的Max-Pooling不同，ROI Poling将输入feature maps划分为固定数量，例如k，的大致相等的区域，然后在每个区域上应用Max-Pooling.因此，无论输入大小如何，POI Pooling的输出始终为k.
  #### 5.四步交替训练
		为了强制网络在RPN和检测器之间共享CNN主干的权重，作者使用了4个步骤的训练方法：
  - RPN是独立训练的，这个任务的主干CNN是由ImageNet分类任务的权重初始化的，之后针对区域建议任务进行微调。
  - Faster-RCNN检测器网络也是独立训练的，这个任务的主干CNN也是由那些来自针对ImageNet分类任务而训练的网络的权重初始化的，之后针对目标检测任务进行微调。RPN的权重是固定的，并且由RPN生成的建议被用来训练Faster-RCNN.
  - 现在RPN被来自Faster-RCNN的权重初始化，然后只对区域建议任务进行微调。这次，位于RPN和检测器之间的共同层保持固定，只有那些对RPN独特的层被微调，这是最终的RPN.
  - Faster-RCNN检测器再次利用新的RPN进行微调。再次，仅对检测器网络唯一的层进行了微调，而公共层权重是固定的。

## 六.训练过程
		将数据集以VOC2007格式呈现之后，均使用VGG16作为预训练模型进行训练。修改模型的参数以适应本次作业的数据集。

## 七.对于遮挡问题的改进
		作业使用Soft NMS算法来改进重叠遮挡问题的改进。Soft NMS对密集物体检测的检测效果有一定的提升作用。
  #### 1.NMS
		NMS是在目标检测算法中必备的后续处理步骤，目的是用来去除重复框，也就是降低误检。NMS算法的过程大概是：首先，根据检测框的分数对它们进行排序，分数最高的框M被选择，其它与框M重合度很高的框（依据事先定义好的一个法制）则被剔除。这个过程在剩下的框中递归地进行。
		那么这种NMS算法会导致下图所示的问题：
  ![img](https://img-blog.csdn.net/20180309200527621?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
		检测算法本应该输出两个框，但是传统的NMS算法可能会把分数较低的绿框过滤掉（如果绿框和红框的IOU大于设定的阈值就会被过滤掉），导致只检测出一个物体。
  #### 2.Soft NMS
		可以看出NMS的过程有些粗暴，因为NMS直接将与被选择的box的IOU大于某个阈值的box的得分置零，于是有了Soft NMS，该算法简单来说就是用一个稍低一点的分数来代替原有的分数，而不是直接置零。另外由于Soft NMS可以很方便地引入到目标检测算法中，不需要重新训练原有的模型，因此这是该算法的一大特点。
		Soft NMS算法过程是：输入为B，S，Nt，含义如下图所示。集合D用来放最终的box,在集合B非空的前提下，搜索集合S中数值最大的数，假设其下标为m,那么M就是选择的框。将M与D集合合并，再循环集合B中的每个box，这个时候就体现了与NMS的差别，如果是传统的NMS操作，那么当B中的box bi和M的IOU值大于阈值Nt,那么就从B和S中去除该box；如果是Soft NMS，则对于B中的box bi也是先计算其和M的IOU，然后该IOU值最为函数f()的输入，最后和bi的分数si相乘作为最后该bi的分数。
  ![img](https://img-blog.csdn.net/20180309200626763?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

		接下来的重点就是如何确定函数f()了。
		对于传统的NMS算法可以用下面的式子表示：

$$
s_{i}=\left\{\begin{array}{ll}{s_{i},} & {\operatorname{iou}\left(\mathcal{M}, b_{i}\right)<N_{t}} \\ {0,} & {\operatorname{iou}\left(\mathcal{M}, b_{i}\right) \geq N_{t}}\end{array}\right.
$$

		为了改进这种粗暴的方法，并遵循IOU越大，得分越低的原则，就会想到下面的公式来表示Soft NMS：

$$
s_{i}=\left\{\begin{array}{ll}{s_{i},} & {\operatorname{iou}\left(\mathcal{M}, b_{i}\right)<N_{t}} \\ {s_{i}\left(1-\operatorname{iou}\left(\mathcal{M}, b_{i}\right)\right),} & {\operatorname{iou}\left(\mathcal{M}, b_{i}\right) \geq N_{t}}\end{array}\right.
$$

		但是上面这个公式是不连续的，这样会导致box集合中的分数出现断层，于是有下面的Soft NMS式子，也是最常用的式子：

$$
s_{i}=s_{i} e^{-\frac{\operatorname{iou}\left(\mathcal{M}, b_{i}\right)^{2}}{\sigma}}, \forall b_{i} \notin \mathcal{D}
$$
		这个式子能保证不存在重叠时没有惩罚，存在越高程度的重叠时，惩罚则越高。

## 八.实验结果
  #### 1.SSD
	AP for 带电芯充电宝 = 0.3351
	AP for 不带电芯充电宝 = 0.2815
	Mean AP = 0.3083
	Results: 0.335 0.282 0.308
  #### 2.Faster-RCNN:
	AP for 带电芯充电宝 = 0.7647
	AP for 不带电芯充电宝 = 0.7653
	Mean AP = 0.7650
	Results: 0.765 0.765 0.765

## 九.模型对比
  - SSD训练速度更快，但当速度并不是严格考虑的对象时，Faster-RCNN要比SSD更好，它的准确率要更高。
  - SSD同样也借鉴了Faster-RCNN的Anchors技术，但由于不是在每个位置上的精调更适合实时的处理。同时其准确率要根据实际的应用来判断是否符合准确率的要求。
  - 在实验过程中也发现，图片的分别率能显著影响模型的准确率，分辨率降低模型准确率能得到提高。

